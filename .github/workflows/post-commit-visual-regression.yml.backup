name: Post-Commit Visual Regression

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      auto_update_golden:
        description: 'Automatically update golden masters if tests fail'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  issues: write
  actions: read

jobs:
  post-commit-visual-test:
    runs-on: [self-hosted, linux, x64]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
    
    - name: Cache cargo dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
    
    - name: Create necessary directories
      run: |
        mkdir -p outputs
        mkdir -p diffs
        mkdir -p golden
    
    - name: Build render_sandbox
      run: |
        cargo build --release
    
    - name: Run all GPU tests
      run: |
        # Run all GPU-requiring tests on this GPU instance
        # This includes visual regression tests that generate test images
        cargo test --release --features gpu-tests -- --nocapture
    
    - name: Upload test outputs as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: post-commit-outputs-${{ github.run_number }}
        path: outputs/
        retention-days: 30
    
    - name: Compare images against golden masters
      id: compare
      continue-on-error: true
      run: |
        set -euo pipefail
        
        # Install NVIDIA FLIP for image comparison
        pip install flip-evaluator
        
        # Initialize variables
        FAILED_IMAGES=""
        FAILURES_DETECTED=false
        TOTAL_TESTS=0
        PASSED_TESTS=0
        FAILED_TESTS=0
        
        # Create detailed report
        echo "# Post-Commit Visual Regression Test Results" > post_commit_report.md
        echo "" >> post_commit_report.md
        echo "**Test Run:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> post_commit_report.md
        echo "**Commit:** ${{ github.sha }}" >> post_commit_report.md
        echo "**Branch:** ${{ github.ref_name }}" >> post_commit_report.md
        echo "" >> post_commit_report.md
        echo "## Summary" >> post_commit_report.md
        echo "" >> post_commit_report.md
        echo "| File | Status | FLIP Mean Error | Result |" >> post_commit_report.md
        echo "|------|--------|-----------------|--------|" >> post_commit_report.md
        
        # Initialize detailed results section
        echo "" > detailed_results.md
        echo "## Detailed Results" >> detailed_results.md
        echo "" >> detailed_results.md
        
        # Process each output image
        if [ ! -d "outputs" ] || [ -z "$(ls -A outputs/*.png 2>/dev/null)" ]; then
          echo "âŒ No output images found in outputs/ directory"
          echo "FAILURES_DETECTED=error" >> $GITHUB_OUTPUT
          echo "The post-commit visual regression test expects images to be generated by the test suite." >> post_commit_report.md
          exit 1
        fi
        
        for output_file in outputs/*.png; do
          if [ ! -f "$output_file" ]; then
            continue
          fi
          
          filename=$(basename "$output_file")
          golden_file="golden/$filename"
          diff_file="diffs/diff_$filename"
          
          TOTAL_TESTS=$((TOTAL_TESTS + 1))
          echo "Processing $filename..."
          
          # Check if golden image exists
          if [ ! -f "$golden_file" ]; then
            # New image - needs golden master
            echo "| \`$filename\` | ðŸ†• New | N/A | Missing golden master |" >> post_commit_report.md
            
            echo "### ðŸ†• $filename (Missing Golden Master)" >> detailed_results.md
            echo "" >> detailed_results.md
            echo "**Status:** No golden master exists for this test image" >> detailed_results.md
            echo "**Action Required:** This indicates either:" >> detailed_results.md
            echo "- A new test was added that needs a golden master" >> detailed_results.md
            echo "- An existing golden master was accidentally deleted" >> detailed_results.md
            echo "" >> detailed_results.md
            echo "**File Size:** $(stat -c%s "$output_file" 2>/dev/null || echo 'Unknown') bytes" >> detailed_results.md
            dimensions=$(python3 -c "from PIL import Image; img = Image.open('$output_file'); print(f'{img.width}x{img.height}')" 2>/dev/null || echo 'Unknown')
            echo "**Dimensions:** $dimensions" >> detailed_results.md
            echo "" >> detailed_results.md
            echo "**Recommendation:** Review this test and create a golden master if appropriate." >> detailed_results.md
            echo "" >> detailed_results.md
            echo "---" >> detailed_results.md
            echo "" >> detailed_results.md
            
            FAILED_IMAGES="$FAILED_IMAGES $filename"
            FAILURES_DETECTED=true
            FAILED_TESTS=$((FAILED_TESTS + 1))
          else
            # Fetch the specific golden LFS file
            git lfs pull --include "$golden_file" || echo "Warning: Could not pull LFS file $golden_file"
            
            # Compare using NVIDIA FLIP
            basename_no_ext=$(basename "$filename" .png)
            diff_basename="diff_${basename_no_ext}"
            
            # Run FLIP comparison
            flip_output=$(flip -r "$golden_file" -t "$output_file" -d diffs -b "$diff_basename" -v 2 -txt 2>&1) || flip_exit_code=$?
            flip_exit_code=${flip_exit_code:-0}
            
            if [ $flip_exit_code -ne 0 ]; then
              echo "| \`$filename\` | âŒ Error | N/A | FLIP failed |" >> post_commit_report.md
              echo "Error: FLIP command failed for $filename"
              FAILED_IMAGES="$FAILED_IMAGES $filename"
              FAILURES_DETECTED=true
              FAILED_TESTS=$((FAILED_TESTS + 1))
              continue
            fi
            
            # Extract FLIP statistics
            mean_error=$(echo "$flip_output" | grep "Mean:" | awk '{print $2}')
            
            # Check if there's a meaningful difference (FLIP error > 0.001)
            is_different=$(echo "$mean_error" | awk '{if ($1 > 0.001) print "yes"; else print "no"}')
            
            if [ "$is_different" = "yes" ]; then
              echo "| \`$filename\` | ðŸ”„ Failed | $mean_error | Visual difference detected |" >> post_commit_report.md
              FAILED_IMAGES="$FAILED_IMAGES $filename"
              FAILURES_DETECTED=true
              FAILED_TESTS=$((FAILED_TESTS + 1))
              
              echo "### ðŸ”„ $filename (Visual Difference Detected)" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "**Status:** Visual differences detected in main branch output" >> detailed_results.md
              echo "**FLIP Mean Error:** ${mean_error:-'N/A'}" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "**Possible Causes:**" >> detailed_results.md
              echo "- Code changes that affect visual output" >> detailed_results.md
              echo "- Environment differences between PR and main branch" >> detailed_results.md
              echo "- Outdated golden master files" >> detailed_results.md
              echo "- GPU driver or dependency changes" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "**Recommendation:** Investigate the visual changes and update golden masters if appropriate." >> detailed_results.md
              echo "" >> detailed_results.md
              echo "---" >> detailed_results.md
              echo "" >> detailed_results.md
            else
              echo "| \`$filename\` | âœ… Passed | $mean_error | No changes |" >> post_commit_report.md
              PASSED_TESTS=$((PASSED_TESTS + 1))
              
              echo "### âœ… $filename (Passed)" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "**Status:** Visual output matches golden master" >> detailed_results.md
              echo "**FLIP Mean Error:** ${mean_error:-'N/A'} (below significance threshold)" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "---" >> detailed_results.md
              echo "" >> detailed_results.md
            fi
          fi
        done
        
        # Add summary statistics
        echo "" >> post_commit_report.md
        echo "**Test Summary:**" >> post_commit_report.md
        echo "- Total Tests: $TOTAL_TESTS" >> post_commit_report.md
        echo "- Passed: $PASSED_TESTS" >> post_commit_report.md
        echo "- Failed: $FAILED_TESTS" >> post_commit_report.md
        echo "" >> post_commit_report.md
        
        # Append detailed results
        cat detailed_results.md >> post_commit_report.md
        
        # Set outputs
        echo "failures_detected=$FAILURES_DETECTED" >> $GITHUB_OUTPUT
        echo "failed_images=$FAILED_IMAGES" >> $GITHUB_OUTPUT
        echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
        echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
        echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
        
        if [ "$FAILURES_DETECTED" = "true" ]; then
          echo "âŒ Post-commit visual regression test detected $FAILED_TESTS failures out of $TOTAL_TESTS tests"
          exit 1
        else
          echo "âœ… All $TOTAL_TESTS post-commit visual regression tests passed"
        fi
    
    - name: Auto-update golden masters (if enabled)
      if: failure() && steps.compare.outputs.failures_detected == 'true' && (github.event.inputs.auto_update_golden == 'true' || github.event_name == 'workflow_dispatch')
      run: |
        echo "ðŸ”„ Auto-updating golden masters..."
        
        # Configure git
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        FAILED_IMAGES="${{ steps.compare.outputs.failed_images }}"
        UPDATED_COUNT=0
        
        for filename in $FAILED_IMAGES; do
          output_file="outputs/$filename"
          golden_file="golden/$filename"
          
          if [ -f "$output_file" ]; then
            echo "Updating golden master for $filename"
            cp "$output_file" "$golden_file"
            git add "$golden_file"
            UPDATED_COUNT=$((UPDATED_COUNT + 1))
          fi
        done
        
        if [ $UPDATED_COUNT -gt 0 ]; then
          COMMIT_MSG="Auto-update golden masters after post-commit visual regression

Updated $UPDATED_COUNT golden master(s): $FAILED_IMAGES

Commit: ${{ github.sha }}
Run: ${{ github.run_id }}"
          git commit -m "$COMMIT_MSG"
          git push
          echo "âœ“ Updated $UPDATED_COUNT golden master files"
        else
          echo "âœ— No golden masters to update"
        fi
    
    - name: Create GitHub issue for failures
      if: failure() && steps.compare.outputs.failures_detected == 'true' && github.event.inputs.auto_update_golden != 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          try {
            const report = fs.readFileSync('post_commit_report.md', 'utf8');
            const failedTests = '${{ steps.compare.outputs.failed_tests }}';
            const totalTests = '${{ steps.compare.outputs.total_tests }}';
            const commitSha = '${{ github.sha }}';
            const runId = '${{ github.run_id }}';
            
            const issueTitle = `ðŸ” Post-Commit Visual Regression Failures (${failedTests}/${totalTests} tests failed)`;
            
            const issueBody = `${report}

## Actions Required

1. **Review the visual differences** in the workflow artifacts
2. **Investigate the cause** of the visual changes:
   - Code changes that affect rendering
   - Environment differences
   - Outdated golden masters
   - GPU driver or dependency changes
3. **Update golden masters if appropriate** by:
   - Running the workflow manually with "auto_update_golden" enabled
   - Or manually updating the golden master files in a PR

## Workflow Information

- **Commit:** ${commitSha}
- **Workflow Run:** [View Details](https://github.com/${{ github.repository }}/actions/runs/${runId})
- **Artifacts:** [Download Test Results](https://github.com/${{ github.repository }}/actions/runs/${runId})

## Quick Fix

If these visual changes are expected, you can automatically update the golden masters by:
1. Go to [Actions](https://github.com/${{ github.repository }}/actions/workflows/post-commit-visual-regression.yml)
2. Click "Run workflow"
3. Enable "Automatically update golden masters if tests fail"
4. Click "Run workflow"

This issue will be automatically closed once the visual regression tests pass.`;

            // Check if there's already an open issue for post-commit visual regression
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'visual-regression,post-commit'
            });
            
            const existingIssue = issues.data.find(issue => 
              issue.title.includes('Post-Commit Visual Regression Failures')
            );
            
            if (existingIssue) {
              // Update existing issue
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                title: issueTitle,
                body: issueBody
              });
              
              console.log(`Updated existing issue: ${existingIssue.html_url}`);
            } else {
              // Create new issue
              const newIssue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['visual-regression', 'post-commit', 'bug']
              });
              
              console.log(`Created new issue: ${newIssue.data.html_url}`);
            }
            
          } catch (error) {
            console.error('Failed to create/update issue:', error.message);
            console.log('Report content would have been:');
            try {
              const report = fs.readFileSync('post_commit_report.md', 'utf8');
              console.log(report);
            } catch (reportError) {
              console.log('Could not read report file');
            }
          }
    
    - name: Close resolved issues
      if: success() && steps.compare.outputs.failures_detected == 'false'
      uses: actions/github-script@v7
      with:
        script: |
          // Close any open post-commit visual regression issues since tests are now passing
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            labels: 'visual-regression,post-commit'
          });
          
          for (const issue of issues.data) {
            if (issue.title.includes('Post-Commit Visual Regression Failures')) {
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issue.number,
                state: 'closed',
                state_reason: 'completed'
              });
              
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issue.number,
                body: `âœ… **Visual regression tests are now passing!**

All post-commit visual regression tests passed successfully in commit ${{ github.sha }}.

**Workflow Run:** [View Details](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

This issue is being automatically closed.`
              });
              
              console.log(`Closed resolved issue: ${issue.html_url}`);
            }
          }
    
    - name: Upload complete results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: post-commit-visual-results-${{ github.run_number }}
        path: |
          outputs/
          diffs/
          golden/
          post_commit_report.md
        retention-days: 30