name: Visual Diff and PR Report

on:
  pull_request:
    types: [opened, synchronize]
  workflow_dispatch:

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  generate-images:
    runs-on: [self-hosted, linux, x64]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
    
    - name: Cache cargo dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
    
    - name: Create necessary directories
      run: |
        mkdir -p outputs
        mkdir -p diffs
        mkdir -p golden
    
    - name: Build render_sandbox
      run: |
        cargo build --release
    
    - name: Generate test outputs via cargo test
      run: |
        # Run visual regression tests which generate output images using the application
        # Enable gpu-tests feature to run GPU-requiring tests on this GPU instance
        cargo test generate_visual_regression_images --release --features gpu-tests -- --exact --nocapture
    
    - name: Upload test outputs
      uses: actions/upload-artifact@v4
      with:
        name: test-outputs-${{ github.event.pull_request.number || github.run_number }}
        path: outputs/
        retention-days: 30

  call-visual-diff:
    needs: generate-images
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
      pull-requests: write
      actions: read  # Needed for artifact access
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Download test outputs from generate-images job
      uses: actions/download-artifact@v4
      with:
        name: test-outputs-${{ github.event.pull_request.number || github.run_number }}
        path: ./
    
    - name: Install NVIDIA FLIP for image comparison
      run: |
        # Install NVIDIA FLIP from PyPI for high-fidelity image comparison
        pip install flip-evaluator
        flip --help
    
    - name: Create necessary directories
      run: |
        mkdir -p diffs
        mkdir -p golden
    
    - name: Compare images and generate diffs
      id: compare
      run: |
        set -euo pipefail  # Enable strict error handling
        
        OUTPUTS_DIR="outputs"
        
        # Initialize variables
        CHANGED_IMAGES=""
        CHANGES_DETECTED=false
        
        # Create comparison report with summary table
        echo "# Visual Regression Test Results" > comparison_report.md
        echo "" >> comparison_report.md
        echo "**Test Run:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> comparison_report.md
        echo "" >> comparison_report.md
        echo "## Summary" >> comparison_report.md
        echo "" >> comparison_report.md
        echo "| File | Status | FLIP Mean Error | Result |" >> comparison_report.md
        echo "|------|--------|-----------------|--------|" >> comparison_report.md
        
        # Initialize summary data and detailed results
        summary_data=""
        
        # Initialize detailed results section
        echo "" > detailed_results.md
        echo "## Detailed Results" >> detailed_results.md
        echo "" >> detailed_results.md
        
        # Check if test images exist
        if [ ! -d "$OUTPUTS_DIR" ] || [ -z "$(ls -A $OUTPUTS_DIR/ 2>/dev/null)" ]; then
          echo "❌ No test images found in $OUTPUTS_DIR/ directory"
          exit 1
        fi
        
        # Process each output image
        for output_file in "$OUTPUTS_DIR"/*.png; do
          if [ ! -f "$output_file" ]; then
            echo "No output images found"
            continue
          fi
          
          filename=$(basename "$output_file")
          golden_file="golden/$filename"
          diff_file="diffs/diff_$filename"
          
          echo "Processing $filename..."
          
          # Check if golden image exists
          if [ ! -f "$golden_file" ]; then
            # New image - no golden master exists
            summary_data="$summary_data| \`$filename\` | 🆕 New | N/A | Needs acceptance |\n"
            
            # Add detailed analysis for new image
            echo "### 🆕 $filename (New Image)" >> detailed_results.md
            echo "" >> detailed_results.md
            echo "**Status:** New image detected - no golden master exists" >> detailed_results.md
            echo "**Action Required:** This image needs to be accepted as a new golden master" >> detailed_results.md
            echo "" >> detailed_results.md
            echo "To accept this new image: \`/accept-image $filename\`" >> detailed_results.md
            echo "" >> detailed_results.md
            echo "---" >> detailed_results.md
            echo "" >> detailed_results.md
            
            CHANGED_IMAGES="$CHANGED_IMAGES $filename"
            CHANGES_DETECTED=true
          else
            # Fetch the specific golden LFS file
            git lfs pull --include "$golden_file"
            
            # Compare using NVIDIA FLIP for high-fidelity comparison
            basename_no_ext=$(basename "$filename" .png)
            diff_basename="diff_${basename_no_ext}"
            
            # Run FLIP with enhanced verbosity and text output for detailed statistics
            flip_output=$(flip -r "$golden_file" -t "$output_file" -d diffs -b "$diff_basename" -v 2 -txt 2>&1)
            flip_exit_code=$?
            
            # Check if FLIP command succeeded
            if [ $flip_exit_code -ne 0 ]; then
              echo "Error: FLIP command failed with exit code $flip_exit_code"
              summary_data="$summary_data| \`$filename\` | ❌ Error | N/A | FLIP failed |\n"
              continue
            fi
            
            # Extract FLIP statistics
            mean_error=$(echo "$flip_output" | grep "Mean:" | awk '{print $2}')
            
            # Check if there's any meaningful difference (FLIP error > 0.001)
            is_different=$(echo "$mean_error" | awk '{if ($1 > 0.001) print "yes"; else print "no"}')
            
            if [ "$is_different" = "yes" ]; then
              summary_data="$summary_data| \`$filename\` | 🔄 Changed | $mean_error | Needs review |\n"
              CHANGED_IMAGES="$CHANGED_IMAGES $filename"
              CHANGES_DETECTED=true
              
              # Add detailed analysis for changed image
              echo "### 🔄 $filename (Changed)" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "**Status:** Visual differences detected" >> detailed_results.md
              echo "**FLIP Mean Error:** ${mean_error:-'N/A'}" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "To accept this change: \`/accept-image $filename\`" >> detailed_results.md
              echo "" >> detailed_results.md
              echo "---" >> detailed_results.md
              echo "" >> detailed_results.md
            else
              summary_data="$summary_data| \`$filename\` | ✅ Passed | $mean_error | No changes |\n"
            fi
          fi
        done
        
        # Add summary data to report
        echo -e "$summary_data" >> comparison_report.md
        echo "" >> comparison_report.md
        
        # Append detailed results to the main report
        cat detailed_results.md >> comparison_report.md
        
        # Set outputs for next steps
        echo "changes_detected=$CHANGES_DETECTED" >> $GITHUB_OUTPUT
        echo "changed_images=$CHANGED_IMAGES" >> $GITHUB_OUTPUT
        
        # If no changes, add a success message
        if [ "$CHANGES_DETECTED" = "false" ]; then
          echo "✅ **All visual tests passed!** No differences detected." >> comparison_report.md
        fi
    
    - name: Upload comparison results
      uses: actions/upload-artifact@v4
      with:
        name: visual-test-results-${{ github.event.pull_request.number || github.run_number }}
        path: |
          outputs/
          diffs/
          golden/
          comparison_report.md
        retention-days: 30
    
    - name: Comment PR with results
      if: steps.compare.outputs.changes_detected == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('comparison_report.md', 'utf8');
          
          // Clean up old bot comments first
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          
          const botComments = comments.data.filter(comment => 
            comment.user.type === 'Bot' && 
            (comment.body.includes('Visual Regression Test Results') ||
             comment.body.includes('Visual tests passed'))
          );
          
          // Delete old bot comments to avoid confusion
          for (const comment of botComments) {
            try {
              await github.rest.issues.deleteComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: comment.id
              });
            } catch (error) {
              console.log(`Failed to delete comment ${comment.id}: ${error.message}`);
            }
          }
          
          // Create new comment with results
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: report
          });
    
    - name: Comment PR with success
      if: steps.compare.outputs.changes_detected == 'false'
      uses: actions/github-script@v7
      with:
        script: |
          const report = "✅ **Visual tests passed!** No differences detected.\n\n**Test Run:** " + new Date().toISOString().replace('T', ' ').substr(0, 19) + " UTC";
          
          // Clean up old bot comments first
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          
          const botComments = comments.data.filter(comment => 
            comment.user.type === 'Bot' && 
            (comment.body.includes('Visual Regression Test Results') ||
             comment.body.includes('Visual tests passed'))
          );
          
          // Delete old bot comments to avoid confusion
          for (const comment of botComments) {
            try {
              await github.rest.issues.deleteComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: comment.id
              });
            } catch (error) {
              console.log(`Failed to delete comment ${comment.id}: ${error.message}`);
            }
          }
          
          // Create new comment
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: report
          });
    
    - name: Fail if changes detected but not accepted
      if: steps.compare.outputs.changes_detected == 'true'
      run: |
        echo "Visual regression tests detected changes that need to be reviewed and accepted."
        echo "Use '/accept-image <filename>' commands in PR comments to accept changes."
        exit 1